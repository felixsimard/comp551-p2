{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P2-TextClassification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNeEebhvRFUWNgQmcAFL1Se",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felixsimard/comp551-p2/blob/main/P2_TextClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbG4Bt9E_8Vo"
      },
      "source": [
        "## **Part 2: Text Classification (20 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WmKddKN_6uG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdd9e142-ff60-4df2-dc78-58446ed6c6a9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "import joblib\n",
        "import re\n",
        "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Constants\n",
        "\n",
        "contractions_dict = {\"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\"}\n",
        "# Regular expression for finding contractions\n",
        "contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "lMaOcm5_B-iT",
        "outputId": "7c2b9aa8-41ec-4903-db06-d7c71e3bac8d"
      },
      "source": [
        "# Define dataset paths\n",
        "fake_new_train_dir = r'fake_news/fake_news_train.csv'\n",
        "fake_news_val_dir = r'fake_news/fake_news_val.csv'\n",
        "fake_news_test_dir = r'fake_news/fake_news_test.csv'\n",
        "\n",
        "# Load datasets\n",
        "fake_news_train = pd.read_csv(fake_new_train_dir, engine=\"python\", error_bad_lines=False)\n",
        "fake_news_val = pd.read_csv(fake_news_val_dir, engine=\"python\", error_bad_lines=False)\n",
        "fake_news_test = pd.read_csv(fake_news_test_dir, engine=\"python\", error_bad_lines=False)\n",
        "\n",
        "fake_news_train"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Indian fruit is so important to so many people...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FORT WORTH, Texas — Urú Inc. will hold a confe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>With three of the four new carriers, the Niger...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Let's start with the classic annual dividend r...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Following are some of the major events to have...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>Warning: small, petty spoilers for the Game of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>Shilpa Shetty will soon make her Bollywood deb...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>Add a digital black hole image to the Allstate...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>Share\\nThe name W. L. Gore &amp; Associates might ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>A comprehensive report recapping developments ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  label\n",
              "0      Indian fruit is so important to so many people...      0\n",
              "1      FORT WORTH, Texas — Urú Inc. will hold a confe...      0\n",
              "2      With three of the four new carriers, the Niger...      0\n",
              "3      Let's start with the classic annual dividend r...      0\n",
              "4      Following are some of the major events to have...      1\n",
              "...                                                  ...    ...\n",
              "19995  Warning: small, petty spoilers for the Game of...      1\n",
              "19996  Shilpa Shetty will soon make her Bollywood deb...      0\n",
              "19997  Add a digital black hole image to the Allstate...      0\n",
              "19998  Share\\nThe name W. L. Gore & Associates might ...      1\n",
              "19999  A comprehensive report recapping developments ...      1\n",
              "\n",
              "[20000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njJUff6sCIxA"
      },
      "source": [
        "#### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs8JYBS6DAuu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "635c31eb-d41c-40c2-f631-5c0ee2daf92e"
      },
      "source": [
        "# Stemmer function\n",
        "def apply_stemmer(text):\n",
        "    # stemmer= PorterStemmer()\n",
        "    stemmer = SnowballStemmer(\"english\")\n",
        "    input_str = word_tokenize(text)\n",
        "    stem_lst = []\n",
        "    for word in input_str:\n",
        "        word_stem = stemmer.stem(word)\n",
        "        stem_lst.append(word_stem)\n",
        "    \n",
        "    stem_str = \" \".join(stem_lst)\n",
        "    return stem_str\n",
        "\n",
        "# Expanding contractions\n",
        "# Reference: https://www.analyticsvidhya.com/blog/2021/06/must-known-techniques-for-text-preprocessing-in-nlp/\n",
        "def expand_contractions(text,contractions_dict=contractions_dict):\n",
        "    def replace(match):\n",
        "        return contractions_dict[match.group(0)]\n",
        "    return contractions_re.sub(replace, text)\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess(df):\n",
        "\n",
        "    # Lowercase everything\n",
        "    df['text'] = df['text'].str.lower()\n",
        "\n",
        "    # Expand contractions\n",
        "    # Reference: https://www.analyticsvidhya.com/blog/2021/06/must-known-techniques-for-text-preprocessing-in-nlp/\n",
        "    df['text'] = df['text'].apply(lambda x : expand_contractions(x))\n",
        "\n",
        "    # Remove ponctuation\n",
        "    df['text'] = df['text'].replace(r'[^\\w\\s]', r'', regex=True)\n",
        "\n",
        "    # Remove numbers\n",
        "    df['text'] = df['text'].replace(r'\\d', r'', regex=True)\n",
        "\n",
        "    # Remove special characters (eg: \\n)\n",
        "    df['text'] = df['text'].replace(r'\\\\[a-z]', r'', regex=True)\n",
        "\n",
        "    # Stemming\n",
        "    # df['text'] = df.apply(lambda row: apply_stemmer(row['text']), axis=1)\n",
        "\n",
        "    # Trim whitespaces\n",
        "    df['text'] = df['text'].str.strip()\n",
        "\n",
        "    # Bag of words + Tokenization\n",
        "    vect = CountVectorizer(stop_words=ENGLISH_STOP_WORDS)\n",
        "    X_train_counts = vect.fit_transform(df.text)\n",
        "    joblib.dump(vect, \"vectorizer.pkl\")\n",
        "    print(\"Vectorizer vocabulary:\", vect.vocabulary_.get(u'algorithm'))\n",
        "    print(\"Count Vectorizer shape:\", X_train_counts.shape)\n",
        "    \n",
        "\n",
        "    # TF-IDF representation using bag-of-words matrix\n",
        "    tfidf_transform = TfidfTransformer()\n",
        "    X_train_tfidf = tfidf_transform.fit_transform(X_train_counts)\n",
        "    joblib.dump(tfidf_transform, \"tfidf_transform.pkl\")\n",
        "    print(\"TF-IDF shape:\", X_train_tfidf.shape)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    return X_train_tfidf, df\n",
        "\n",
        "fake_news_train_preprocessed_tfidf, fake_news_train_preprocessed = preprocess(fake_news_train)\n",
        "fake_news_train_preprocessed"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorizer vocabulary: 4050\n",
            "Count Vectorizer shape: (20000, 175918)\n",
            "TF-IDF shape: (20000, 175918)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>indian fruit is so important to so many people...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fort worth texas  urú inc will hold a conferen...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>with three of the four new carriers the nigeri...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>let is start with the classic annual dividend ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>following are some of the major events to have...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>warning small petty spoilers for the game of t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>shilpa shetty will soon make her bollywood deb...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>add a digital black hole image to the allstate...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>share\\nthe name w l gore  associates might not...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>a comprehensive report recapping developments ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  label\n",
              "0      indian fruit is so important to so many people...      0\n",
              "1      fort worth texas  urú inc will hold a conferen...      0\n",
              "2      with three of the four new carriers the nigeri...      0\n",
              "3      let is start with the classic annual dividend ...      0\n",
              "4      following are some of the major events to have...      1\n",
              "...                                                  ...    ...\n",
              "19995  warning small petty spoilers for the game of t...      1\n",
              "19996  shilpa shetty will soon make her bollywood deb...      0\n",
              "19997  add a digital black hole image to the allstate...      0\n",
              "19998  share\\nthe name w l gore  associates might not...      1\n",
              "19999  a comprehensive report recapping developments ...      1\n",
              "\n",
              "[20000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WotyYfhMsby",
        "outputId": "e07faf4a-b34d-4a21-c41e-1bf9408d0d70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "fake_news_train_preprocessed.iloc[0]['text']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'indian fruit is so important to so many people now that the season has come to an end the first stop is to pick something fresh and tangy with some sugar\\nchopped papaya and apple is a little more complicated and some good fats come in other sugar as well milk and almonds are two great sources of fats as well as a couple of fruits such as avocados and okra the result is such a healthy delicious appletoberry spread\\neasy yummy and delicious\\n oz apple or applelivered bon bons\\n tbsp sugar\\n tsp almond extract\\nfreshly ground black pepper\\n tbsp rice vinegar\\n\\n thick and lightflavored bon bons\\nseason with salt and pepper to taste and vary thickness\\nto finish add the fruit to the bowl of a small mixer fitted with a large paddle attachment line a bowl with nonstick cooking spray if using spatula for these meals add enough sugar and almond extract to shake off any excess\\nwhen the mixture is thick and solid remove the bowl from the mixer with a slotted spoon and mix again\\nworking with a spatula or ballerina fold in the sugar as needed and combine with the egg mixture rice vinegar almond extract and stir in the berries stirfry until combined about  to  minutes this should be done before serving\\nnutrition information per serving  calories  g fat  g saturated fat  mg cholesterol  g carbohydrates  g sugar  g protein  mg sodium  g fiber\\nview more oils discovered in local salad dressings\\ninstructions\\nplace the shredded bon bons in a food processor process until smooth use a sharp knife to remove the chunks place the bowl in the fruit bowl and grind for  minutes in a small bowl combine the apples and any fat or oils that have been drained\\nmeanwhile cut the fruit into wedges garnish with lemon slices and serve\\nrecipe courtesy of pieflix not a major health food chain to see more of the recipes go to pieflixcom\\nreceive email alerts for canadian food stories from kitchen gadgets'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoPDM3sMp7k_"
      },
      "source": [
        "#### Model Training, Validation, Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOJWhGdHpjuX"
      },
      "source": [
        "def train_model(x_train, y_train):\n",
        "    # preprocess x_train\n",
        "    x_train_preprocessed_tfidf, x_train_preprocessed  = preprocess(x_train)\n",
        "\n",
        "    # fit model\n",
        "    model = LogisticRegression().fit(x_train_preprocessed_tfidf, y_train)\n",
        "    training_score = model.score(x_train_preprocessed_tfidf, y_train)\n",
        "    joblib.dump(train_model, \"model.pkl\")\n",
        "\n",
        "    print(\"Training score:\", training_score)\n",
        "\n",
        "    return model\n",
        "\n",
        "def transform_preprocess(x_test):\n",
        "    # Load saved pickles\n",
        "    loaded_vectorizer = joblib.load(\"vectorizer.pkl\")\n",
        "    loaded_tfidf_transform = joblib.load(\"tfidf_transform.pkl\")\n",
        "    loaded_model = joblib.load(\"model.pkl\")\n",
        "\n",
        "    # Transform\n",
        "    x_val_vec = loaded_vectorizer.transform(x_test)\n",
        "    x_val_tfidf = loaded_tfidf_transform.transform(x_val_vec)\n",
        "\n",
        "    return x_val_tfidf\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXH_LHDasBQZ",
        "outputId": "e972587d-62b9-4535-851e-2d81699c4f58"
      },
      "source": [
        "# Train model\n",
        "trained_model = train_model(fake_news_train, fake_news_train['label'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorizer vocabulary: 4050\n",
            "Count Vectorizer shape: (20000, 175918)\n",
            "TF-IDF shape: (20000, 175918)\n",
            "\n",
            "\n",
            "Training score: 0.85335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxGFYrhyt_0N",
        "outputId": "25e8a1b9-b38f-4ba4-ed4d-30b87ba77c3b"
      },
      "source": [
        "# Test set\n",
        "x_test_tfidf = transform_preprocess(fake_news_test['text'])\n",
        "y_predictions = trained_model.predict(x_test_tfidf)\n",
        "\n",
        "acc_score = accuracy_score(fake_news_test['label'], y_predictions)\n",
        "print(\"Accuracy on test set:\", acc_score)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 0.6746666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpoMyghbtjHf"
      },
      "source": [
        "\n",
        "    \n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApfBKB7exSqa"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}